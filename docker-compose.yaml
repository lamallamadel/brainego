version: '3.8'

services:
  max-serve-llama:
    image: modular/max-serve:latest
    container_name: max-serve-llama
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models
      - ./configs:/configs
      - ./logs:/logs
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    command: >
      max-serve
      --model-path /models/llama-3.3-8b-instruct-q4_k_m.gguf
      --host 0.0.0.0
      --port 8080
      --max-batch-size 32
      --max-waiting-time 10
      --max-tokens 2048
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  max-serve-qwen:
    image: modular/max-serve:latest
    container_name: max-serve-qwen
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8081:8081"
    volumes:
      - ./models:/models
      - ./configs:/configs
      - ./logs:/logs
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    command: >
      max-serve
      --model-path /models/qwen2.5-coder-7b-instruct-q4_k_m.gguf
      --host 0.0.0.0
      --port 8081
      --max-batch-size 32
      --max-waiting-time 10
      --max-tokens 4096
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  max-serve-deepseek:
    image: modular/max-serve:latest
    container_name: max-serve-deepseek
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8082:8082"
    volumes:
      - ./models:/models
      - ./configs:/configs
      - ./logs:/logs
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    command: >
      max-serve
      --model-path /models/deepseek-r1-distill-qwen-7b-q4_k_m.gguf
      --host 0.0.0.0
      --port 8082
      --max-batch-size 32
      --max-waiting-time 10
      --max-tokens 4096
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  api-server:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: api-server
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8000:8000"
      - "8001:8001"
    volumes:
      - ./configs:/app/configs:ro
    environment:
      - AGENT_ROUTER_CONFIG=/app/configs/agent-router.yaml
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION=documents
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=neo4j_password
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ai_platform
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_password
    depends_on:
      max-serve-llama:
        condition: service_healthy
      max-serve-qwen:
        condition: service_healthy
      max-serve-deepseek:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  gateway:
    build:
      context: .
      dockerfile: Dockerfile.gateway
    container_name: gateway
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "9002:9002"
    volumes:
      - ./configs:/app/configs:ro
    environment:
      - AGENT_ROUTER_CONFIG=/app/configs/agent-router.yaml
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION=documents
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - API_KEYS=${API_KEYS:-}
    depends_on:
      max-serve-llama:
        condition: service_healthy
      max-serve-qwen:
        condition: service_healthy
      max-serve-deepseek:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  mcpjungle-gateway:
    build:
      context: .
      dockerfile: Dockerfile.mcpjungle
    container_name: mcpjungle-gateway
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "9100:9100"
    volumes:
      - ./configs:/app/configs:ro
      - ./workspace:/workspace
    environment:
      - AGENT_ROUTER_CONFIG=/app/configs/agent-router.yaml
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION=documents
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - API_KEYS=${API_KEYS:-}
      - ENABLE_TELEMETRY=true
      - OTLP_ENDPOINT=http://jaeger:4317
      - JAEGER_ENDPOINT=jaeger:6831
      - MCP_SERVERS_CONFIG=/app/configs/mcp-servers.yaml
      - MCP_ACL_CONFIG=/app/configs/mcp-acl.yaml
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - NOTION_API_KEY=${NOTION_API_KEY:-}
    depends_on:
      max-serve-llama:
        condition: service_healthy
      max-serve-qwen:
        condition: service_healthy
      max-serve-deepseek:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
      jaeger:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: jaeger
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "4317:4317"
      - "4318:4318"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
    volumes:
      - jaeger-data:/badger

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts/postgres:/docker-entrypoint-initdb.d
    environment:
      - POSTGRES_DB=ai_platform
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_password
      - PGDATA=/var/lib/postgresql/data/pgdata
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_user -d ai_platform"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  minio:
    image: minio/minio:latest
    container_name: minio
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  neo4j:
    image: neo4j:5.15-community
    container_name: neo4j
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    environment:
      - NEO4J_AUTH=neo4j/neo4j_password
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_memory_heap_initial__size=512M
      - NEO4J_dbms_memory_heap_max__size=1G
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*
      - NEO4JLABS_PLUGINS=["apoc"]
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:7474"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  data-collection:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: data-collection
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8002:8002"
    volumes:
      - ./configs:/app/configs:ro
    environment:
      - DATA_COLLECTION_PORT=8002
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - GITHUB_DEFAULT_REPO=${GITHUB_DEFAULT_REPO:-}
      - GITHUB_WEBHOOK_SECRET=${GITHUB_WEBHOOK_SECRET:-}
      - NOTION_API_KEY=${NOTION_API_KEY:-}
      - NOTION_WEBHOOK_SECRET=${NOTION_WEBHOOK_SECRET:-}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN:-}
      - SLACK_CHANNELS=${SLACK_CHANNELS:-}
      - COLLECTION_CONFIG=/app/configs/collection-schedule.yaml
    depends_on:
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    command: python data_collection_service.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  ingestion-worker:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: ingestion-worker
    restart: unless-stopped
    networks:
      - ai-platform-net
    volumes:
      - ./configs:/app/configs:ro
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - NUM_WORKERS=4
    depends_on:
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      data-collection:
        condition: service_healthy
    command: python worker_service.py

  learning-engine:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: learning-engine
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8003:8003"
    volumes:
      - ./models:/models
      - ./configs:/app/configs:ro
      - ./lora_adapters:/lora_adapters
      - ./fisher_matrices:/fisher_matrices
    environment:
      - LEARNING_ENGINE_HOST=0.0.0.0
      - LEARNING_ENGINE_PORT=8003
      - BASE_MODEL_PATH=/models/llama-3.3-8b-instruct-q4_k_m.gguf
      - MODEL_NAME=meta-llama/Llama-3.3-8B-Instruct
      - LORA_RANK=16
      - LORA_ALPHA=32
      - LORA_DROPOUT=0.05
      - EWC_LAMBDA=500.0
      - BATCH_SIZE=4
      - LEARNING_RATE=2e-4
      - NUM_TRAIN_EPOCHS=3
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin123
      - MINIO_BUCKET=lora-adapters
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ai_platform
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_password
      - AUTO_TRAIN_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: python learning_engine_service.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  drift-monitor:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: drift-monitor
    restart: unless-stopped
    networks:
      - ai-platform-net
    ports:
      - "8004:8004"
    volumes:
      - ./configs:/app/configs:ro
    environment:
      - DRIFT_MONITOR_HOST=0.0.0.0
      - DRIFT_MONITOR_PORT=8004
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=ai_platform
      - POSTGRES_USER=ai_user
      - POSTGRES_PASSWORD=ai_password
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
      - LEARNING_ENGINE_URL=http://learning-engine:8003
    depends_on:
      postgres:
        condition: service_healthy
      learning-engine:
        condition: service_healthy
    command: python drift_monitor.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  ai-platform-net:
    driver: bridge
    name: ai-platform-net

volumes:
  qdrant-storage:
    driver: local
  redis-data:
    driver: local
  postgres-data:
    driver: local
  minio-data:
    driver: local
  jaeger-data:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-import:
    driver: local
  neo4j-plugins:
    driver: local
